{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05eb3cde",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "<font>\n",
    "<div dir=ltr align=center>\n",
    "<img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" width=150 height=150> <br>\n",
    "<font color=0F5298 size=7>\n",
    "Artificial Intelligence <br>\n",
    "<font color=2565AE size=5>\n",
    "Computer Engineering Department <br>\n",
    "Spring 2024<br>\n",
    "<font color=3C99D size=5>\n",
    "Practical Assignment 2 - Minimax Algorithm<br>\n",
    "<font color=696880 size=4>\n",
    "Sepehr Harfi\n",
    "\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a011cf",
   "metadata": {},
   "source": [
    "# Personal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d506013",
   "metadata": {},
   "outputs": [],
   "source": [
    "Student_number = \"400104801\"\n",
    "Name = \"Mehran\"\n",
    "Last_name = \"Bakhtiari\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de0ad2",
   "metadata": {},
   "source": [
    "# Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf03f32",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "Please run all the cells.\n",
    "\n",
    "Please refrain from making any changes to the existing files, such as `board.py`, `game.py`, etc. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f884c",
   "metadata": {},
   "source": [
    "#### **Note:** It is strongly recommended to execute this notebook on your local device instead of Google Colab due to limitations with graphics. However, if you still prefer using Google Colab, you can refer to this [link](https://vishnudsharma.medium.com/visualizing-tkinter-and-pygame-in-colab-272c5a245f8c) for assistance in using graphics with Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3fdd74",
   "metadata": {},
   "source": [
    "# Libraries & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94534a71",
   "metadata": {},
   "source": [
    "**Dont change the below cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e4bb0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "curr_working_directory = os.getcwd()\n",
    "src_directory_path = os.path.join(curr_working_directory, \"src\")\n",
    "\n",
    "if os.path.exists(src_directory_path):\n",
    "    os.chdir(src_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bcdc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import game\n",
    "from player import Player\n",
    "from random_player import RandomPlayer\n",
    "from random_greedy_player import RandomGreedyPlayer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf190d9",
   "metadata": {
    "id": "5cf190d9"
   },
   "source": [
    "\n",
    "# Breakthrough Game: Minimax and AlphaBeta Players (100 Points)\n",
    "\n",
    "In this notebook, we will implement and compare two AI strategies, Minimax and AlphaBeta, for playing a simple version of the Breakthrough game. We aim to assess the performance of these strategies in terms of their execution time and win probability in matches against a Greedy player and against each other with varying depths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba059eaf",
   "metadata": {},
   "source": [
    "# Breakthrough Game Rules\n",
    "\n",
    "The Breakthrough game is a two-player strategy board game played on an 6x6 grid. The objective of the game is to move your pieces from one end of the board to the other before your opponent does.\n",
    "\n",
    "## Game Setup\n",
    "\n",
    "- The board consists of a 6x6 grid with alternating dark and light squares.\n",
    "- Each player starts with 12 pieces placed on their respective sides of the board.\n",
    "- The pieces are initially arranged in two rows, with each row containing 6 pieces.\n",
    "\n",
    "## Piece Movement\n",
    "\n",
    "- Each player can only move their own pieces.\n",
    "- Pieces can move diagonally or straight forward one square at a time.\n",
    "- Pieces cannot move backward or sideways.\n",
    "- Pieces can capture their opponent's pieces by moving diagonally forward and landing on a square occupied by an opponent's piece.\n",
    "- Captured pieces are removed from the board.\n",
    "\n",
    "\n",
    "## Game End\n",
    "\n",
    "- If a player successfully moves one of their pieces to the opposite end of the board, they win the game.\n",
    "\n",
    "## Additional Rules\n",
    "\n",
    "- Players can only capture the opponent's piece if its in their diagonal forward squares and they cannot have two or more pieces of their color in the same square.\n",
    "- Players take turns moving their pieces.\n",
    "- Players must make a move on their turn, and they cannot skip their turn.\n",
    "- If a player has multiple legal moves, they can choose which piece to move."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe681eb",
   "metadata": {
    "id": "ffe681eb"
   },
   "source": [
    "\n",
    "## Demo of the game with graphics\n",
    "\n",
    "Initially, using the cell below, you can see a demo gameplay of two Random Greedy Players to gain insights into the game. Additionally, you can explore the gameplay of other agents such as \"Player\" which plays in a complete greedy way and also \"RandomPlayer\", to further enhance your understanding of the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02c41b4",
   "metadata": {},
   "source": [
    "**Note:** You can use the cell below anywhere you want to see the game with the graphics. For this purpose, you should only be careful to pass the right class of players to the `game.Game()`. Also, If you want to see the performance of your Minimax or AlphaBeta agents, you may need to add their classes as a python file to the `src` folder and import their classes in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b067d36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b067d36",
    "is_executing": true,
    "outputId": "c31c275e-abbe-4383-c984-80922eb2d829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: -175.0, 1: 227.0}\n"
     ]
    }
   ],
   "source": [
    "%%python3 \n",
    "# Change the above line to %%python if youre using Windows OS\n",
    "import game\n",
    "from player import Player\n",
    "from random_greedy_player import RandomGreedyPlayer\n",
    "from random_player import RandomPlayer\n",
    "\n",
    "\n",
    "random_greedy_game = game.Game(RandomGreedyPlayer, RandomGreedyPlayer)\n",
    "print(random_greedy_game.play(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac79cb",
   "metadata": {
    "id": "d6ac79cb"
   },
   "source": [
    "\n",
    "## Minimax Agent (30 Points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee44bc1",
   "metadata": {},
   "source": [
    "To gain insights into the game, start by reading the `board.py`, `game.py`, and `player.py` files to understand the game implementation. Then, implement a minimax agent. Recall that the minimax algorithm evaluates game states and selects optimal moves. Compare the performance of the random greedy and minimax agents to gain insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c64f4",
   "metadata": {},
   "source": [
    "**Note:** To implement the Minimax agent, you should only modify the `MinimaxPlayer` class in the cell below. You can either use the Board class `get_scores` function or define your own score funcion here and use it for the evaluation of a board state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dd51e9",
   "metadata": {},
   "source": [
    "**Note:** Your minimax implementation should have a depth instance which determines the level to which the algorithm should be executed for each move. It controls the extent of the search tree explored by the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063de25",
   "metadata": {},
   "source": [
    "**Note:** Feel free to add cells if you need to, but don't erase the existing cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf52f5b",
   "metadata": {},
   "source": [
    "### Implementation (25 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f1a446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimaxPlayer(Player):\n",
    "    def __init__(self, player_number, board, depth=3):\n",
    "        super().__init__(player_number, board)\n",
    "        self.depth = depth\n",
    "\n",
    "    def get_next_move(self):\n",
    "        best_move, _ = self.minimax(self.depth, self.player_number, True)\n",
    "        return best_move\n",
    "\n",
    "    def minimax(self, depth, player, maximizing_player):\n",
    "        if depth == 0 or self.board.is_game_over(self.board.get_board_grid()) != -1:\n",
    "            return None, self.evaluate_board()\n",
    "\n",
    "        if maximizing_player:\n",
    "            max_score = float('-inf')\n",
    "            best_move = None\n",
    "            for move in self.get_possible_moves(player):\n",
    "                self.board.start_imagination()\n",
    "                self.board.place_piece_imaginary(move, player)\n",
    "                _, score = self.minimax(depth - 1, self.opponent_number, False)\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    best_move = move\n",
    "            return best_move, max_score\n",
    "        else:\n",
    "            min_score = float('inf')\n",
    "            best_move = None\n",
    "            for move in self.get_possible_moves(player):\n",
    "                self.board.start_imagination()\n",
    "                self.board.place_piece_imaginary(move, player)\n",
    "                _, score = self.minimax(depth - 1, self.opponent_number, True)\n",
    "                if score < min_score:\n",
    "                    min_score = score\n",
    "                    best_move = move\n",
    "            return best_move, min_score\n",
    "\n",
    "    def evaluate_board(self):\n",
    "        scores = self.board.get_scores(self.board.get_board_grid())\n",
    "        return scores[self.player_number] - scores[self.opponent_number]\n",
    "\n",
    "    def get_possible_moves(self, player):\n",
    "        moves = []\n",
    "        range_n = (0, self.board.get_n()) if player == self.player_number else (self.board.get_n() - 1, -1)\n",
    "        step = 1 if player == self.player_number else -1\n",
    "        for i in range(range_n[0], range_n[1], step):\n",
    "            for j in range(self.board.get_n()):\n",
    "                if self.board.get_board_grid()[i][j] == player:\n",
    "                    for direction in self.board.get_possible_directions(player):\n",
    "                        move = ((i, j), (i + direction[0], j + direction[1]))\n",
    "                        if self.board.is_move_valid(self.board.get_board_grid(), move, player):\n",
    "                            moves.append(move)\n",
    "        return moves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adb6b4c",
   "metadata": {},
   "source": [
    "### Time Analysis (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c148af",
   "metadata": {},
   "source": [
    "Now play the game 5 times between two random players and calculate the average execution time. Also do this for the game of a random player and a minimax player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c27ce0cf",
   "metadata": {
    "id": "c27ce0cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Players Average Execution Time: 0.004776763916015625 seconds\n",
      "Minimax Player and Random Player Average Execution Time: 2.704791212081909 seconds\n"
     ]
    }
   ],
   "source": [
    "from minimax_player import MinimaxPlayer\n",
    "from game import Game\n",
    "\n",
    "def calculate_average_execution_time(player1_class, player2_class, num_games):\n",
    "    total_time = 0\n",
    "    for _ in range(num_games):\n",
    "        start_time = time.time()\n",
    "        game = Game(player1_class, player2_class)\n",
    "        game.play()\n",
    "        end_time = time.time()\n",
    "        total_time += end_time - start_time\n",
    "    return total_time / num_games\n",
    "\n",
    "num_games = 5\n",
    "\n",
    "mean_time_random = calculate_average_execution_time(RandomPlayer, RandomPlayer, num_games)\n",
    "\n",
    "minimax_player = MinimaxPlayer\n",
    "\n",
    "mean_time_minimax = calculate_average_execution_time(RandomPlayer, minimax_player, num_games)\n",
    "\n",
    "print(\"Random Players Average Execution Time:\", mean_time_random, \"seconds\")\n",
    "print(\"Minimax Player and Random Player Average Execution Time:\", mean_time_minimax, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46ed00",
   "metadata": {},
   "source": [
    "## Alphabeta Agent (30 Points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573b1458",
   "metadata": {},
   "source": [
    "As we can see from the above code, the Minimax algorithm takes much longer time to execute. To improve the execution time, we can implement the AlphaBeta pruning algorithm. In the next cell, we will be implementing the AlphaBeta player.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa687f",
   "metadata": {},
   "source": [
    "### Implementation (25 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e20ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaBetaPlayer(Player):\n",
    "    def __init__(self, player_number, board, depth=3):\n",
    "        super().__init__(player_number, board)\n",
    "        self.depth = depth\n",
    "        \n",
    "    def get_scores(self, board):\n",
    "        scores = {0: 0, 1: 0}\n",
    "        for row in range(6):\n",
    "            for col in range(6):\n",
    "                if board[row][col] == 0:\n",
    "                    scores[0] += 1 + (2.0 ** row) * row\n",
    "                elif board[row][col] == 1:\n",
    "                    scores[1] += 1 + (2.0 ** (6 - row - 1)) * (6 - row - 1)\n",
    "        scores[0] += self.board.winning_score(board, 0)\n",
    "        scores[1] += self.board.winning_score(board, 1)\n",
    "        return scores\n",
    "                \n",
    "    def get_next_move(self):\n",
    "        max_score = -float('inf')\n",
    "        best_move = None\n",
    "        for move, i, j, dx, dy in self.get_possible_moves(self.player_number):\n",
    "            self.board.start_imagination()\n",
    "            self.board.place_piece_imaginary(move, self.player_number)\n",
    "            score = self.alphabeta(depth=1, alpha=-float('inf'), beta=float('inf'))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_move = move\n",
    "        return best_move\n",
    "        \n",
    "    def alphabeta(self, depth, alpha, beta):\n",
    "        board = self.board.get_imaginary_board()\n",
    "        if self.board.is_game_over(board) != -1 or depth == self.depth:\n",
    "            scores = self.get_scores(board)\n",
    "            return scores[self.player_number] - scores[self.opponent_number]\n",
    "        \n",
    "        if depth % 2 == 0:\n",
    "            max_score = -float('inf')\n",
    "            for move, i, j, dx, dy in self.get_possible_moves(self.player_number):\n",
    "                previous_destination_value = board[i][j]\n",
    "                self.board.place_piece_imaginary(move, self.player_number)\n",
    "                score = self.alphabeta(depth + 1, alpha, beta)\n",
    "                max_score = max(max_score, score)\n",
    "                board[i][j] = previous_destination_value\n",
    "                board[i + dx][j + dy] = 0\n",
    "                if score >= beta:\n",
    "                    return max_score\n",
    "                alpha = max(alpha, score)\n",
    "            return max_score\n",
    "        else:\n",
    "            min_score = float('inf')\n",
    "            for move, i, j, dx, dy in self.get_possible_moves(self.opponent_number):\n",
    "                previous_destination_value = board[i][j]\n",
    "                self.board.place_piece_imaginary(move, self.opponent_number)\n",
    "                score = self.alphabeta(depth + 1, alpha, beta)\n",
    "                min_score = min(min_score, score)\n",
    "                board[i][j] = previous_destination_value\n",
    "                board[i + dx][j + dy] = 1\n",
    "                if score <= alpha:\n",
    "                    return min_score\n",
    "                beta = min(beta, score)\n",
    "            return min_score\n",
    "        \n",
    "    def get_possible_moves(self, player_number):\n",
    "        moves = []\n",
    "        range_n = (0, self.board.get_n()) if player_number == self.player_number else (self.board.get_n() - 1, -1)\n",
    "        step = 1 if player_number == self.player_number else -1\n",
    "\n",
    "        board = self.board.get_imaginary_board()\n",
    "        if board is None:\n",
    "            return moves\n",
    "        \n",
    "        for i in range(range_n[0], range_n[1], step):\n",
    "            for j in range(range_n[0], range_n[1], step):\n",
    "                if board[i][j] == player_number:\n",
    "                    for direction in self.board.get_possible_directions(player_number):\n",
    "                        move = (i, j), (i + direction[0], j + direction[1])\n",
    "                        if self.board.is_move_valid(board, move, player_number):\n",
    "                            moves.append((move, i, j, direction[0], direction[1]))\n",
    "        return moves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c703a67f",
   "metadata": {},
   "source": [
    "### Time Analysis (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83174e",
   "metadata": {},
   "source": [
    "Now play the game 5 times between the random player and an alphabeta player and calculate the average execution time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bce1a47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabeta Player and Random Player Average Execution Time: 0.514774751663208 seconds\n"
     ]
    }
   ],
   "source": [
    "from alphabeta_player import AlphaBetaPlayer\n",
    "from game import Game\n",
    "\n",
    "def calculate_average_execution_time(player1_class, player2_class, num_games):\n",
    "    total_time = 0\n",
    "    for _ in range(num_games):\n",
    "        start_time = time.time()\n",
    "        game = Game(player1_class, player2_class)\n",
    "        game.play()\n",
    "        end_time = time.time()\n",
    "        total_time += end_time - start_time\n",
    "    return total_time / num_games\n",
    "\n",
    "num_games = 5\n",
    "\n",
    "random_player = RandomPlayer\n",
    "alphabeta_player = AlphaBetaPlayer\n",
    "\n",
    "mean_time_alphabeta = calculate_average_execution_time(random_player, alphabeta_player, num_games)\n",
    "\n",
    "print(\"Alphabeta Player and Random Player Average Execution Time:\", mean_time_alphabeta, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480857e5",
   "metadata": {},
   "source": [
    "##### **Note:** The alphabeta agent should be approximately 5X-10X faster than the minimax player."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6770103",
   "metadata": {
    "id": "c6770103"
   },
   "source": [
    "\n",
    "## Win Probability Analysis (35 Points)\n",
    "\n",
    "In this section, We will simulate 50 games for your AlphaBeta player against other players and analyze their win rates. Additionally, we will have AlphaBeta players with different depths play against each other. \n",
    "\n",
    "Assume you are always the second player and the black player will always start first. \n",
    "\n",
    "If the agent is implemented correctly, with a depth of two or more it should win all the mentioned agents with a win rate > 0.7.\n",
    "\n",
    "**Note:** You can use the `bulk_play` function from `game.py` for this purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb476097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "depths = [1, 2, 3]  # List of different second_player_depth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e54af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results_different_depths(first_player_class, depths, first_player_depth=None, n=50):\n",
    "    results = []\n",
    "    sample_game = game.Game(first_player_class, AlphaBetaPlayer)\n",
    "\n",
    "    for depth in depths:\n",
    "        if first_player_depth is not None:\n",
    "            result = sample_game.bulk_play(n, first_player_depth=first_player_depth, second_player_depth=depth)\n",
    "        else:\n",
    "            result = sample_game.bulk_play(n, second_player_depth=depth)\n",
    "        win_rate = result['white'] / n  # Calculate win rate\n",
    "        results.append({'Depth': depth, 'Win Rate': win_rate})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5361f9",
   "metadata": {},
   "source": [
    "### Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8139c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Depth  Win Rate\n",
      "0      1       1.0\n",
      "1      2       1.0\n",
      "2      3       1.0\n"
     ]
    }
   ],
   "source": [
    "results = compute_results_different_depths(RandomPlayer, depths)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea0e7f",
   "metadata": {},
   "source": [
    "### Random Greedy Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27e22180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Depth  Win Rate\n",
      "0      1       1.0\n",
      "1      2       1.0\n",
      "2      3       1.0\n"
     ]
    }
   ],
   "source": [
    "results = compute_results_different_depths(RandomGreedyPlayer, depths)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e46530",
   "metadata": {},
   "source": [
    "### Greedy Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37408be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Depth  Win Rate\n",
      "0      1       1.0\n",
      "1      2       1.0\n",
      "2      3       1.0\n"
     ]
    }
   ],
   "source": [
    "results = compute_results_different_depths(Player, depths)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3218a4f",
   "metadata": {},
   "source": [
    "### Alphabeta Player with depth 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c7374",
   "metadata": {},
   "source": [
    "**Note:** In this part each game may take up to ~45 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd374cc",
   "metadata": {
    "id": "3cd374cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Depth  Win Rate\n",
      "0      2       0.0\n",
      "1      3       1.0\n",
      "2      4       1.0\n"
     ]
    }
   ],
   "source": [
    "results = compute_results_different_depths(AlphaBetaPlayer, [2, 3, 4], first_player_depth=2, n=30)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873b294",
   "metadata": {
    "id": "4873b294"
   },
   "source": [
    "\n",
    "## Conclusion (5 Points)\n",
    "\n",
    "#### Based on the results of the AlphaBeta player with other players, what is your conclusion?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7783dc",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "Based on the results obtained from simulating games between the AlphaBeta player and other player types, we can draw several conclusions:\n",
    "\n",
    "Random Player: The AlphaBeta player consistently outperforms the Random Player across all depths tested. This is expected since the Random Player makes moves without considering any strategy, while the AlphaBeta player employs a sophisticated search algorithm to select optimal moves.\n",
    "\n",
    "Random Greedy Player: Similar to the Random Player, the AlphaBeta player also dominates the Random Greedy Player across all depths tested. Although the Random Greedy Player has some heuristic strategy (greediness), it's not sufficient to overcome the strategic depth of the AlphaBeta player.\n",
    "\n",
    "Greedy Player: The Greedy Player performs better than the Random Player and the Random Greedy Player. However, it still falls short compared to the AlphaBeta player. The Greedy Player prioritizes immediate gains without considering long-term consequences, whereas the AlphaBeta player looks ahead to future moves to optimize its strategy.\n",
    "\n",
    "AlphaBeta Player with depth 2 vs. depth 2, 3, 4: As expected, increasing the depth of the AlphaBeta player's search generally leads to better performance. However, there might be diminishing returns beyond a certain depth, as the computational complexity increases with depth. In this case, the win rate might not improve significantly beyond a depth of 3.\n",
    "\n",
    "Overall, the results indicate that the AlphaBeta player, especially with deeper search depths, is a strong player capable of consistently outperforming players that lack strategic foresight, such as random or greedy players. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
